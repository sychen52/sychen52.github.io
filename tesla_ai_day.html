<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="generator" content="Org mode" />
<link rel="stylesheet" type="text/css" href="https://orgmode.org/worg/style/worg.css"/>
</head>
<body>
<div id="content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgb98ecfb">Cache feature maps on disk</a></li>
<li><a href="#org4e74b59">Late fusion -&gt; early fusion</a></li>
<li><a href="#orgf35c70a">Transformer for fuse / back-project</a></li>
<li><a href="#org10bba62">Camera rectify</a></li>
<li><a href="#orgd3b169f">Video Queue</a></li>
<li><a href="#orgf89c5af">Spatial RNN</a></li>
</ul>
</div>
</div>
<p>
<a href="https://www.youtube.com/watch?v=j0z4FweCy4M">https://www.youtube.com/watch?v=j0z4FweCy4M</a>
</p>

<div id="outline-container-orgb98ecfb" class="outline-2">
<h2 id="orgb98ecfb">Cache feature maps on disk</h2>
<div class="outline-text-2" id="text-orgb98ecfb">
<ul class="org-ul">
<li>shared back-bone + multiple heads;</li>
<li>back-bone output feature maps are cached on disk;</li>
<li>fine-tune heads based on cached features.</li>
</ul>
</div>
</div>

<div id="outline-container-org4e74b59" class="outline-2">
<h2 id="org4e74b59">Late fusion -&gt; early fusion</h2>
<div class="outline-text-2" id="text-org4e74b59">
<ul class="org-ul">
<li>vector space: 3d space, 2d birds-eye view
From the later slides (Multi-Cam Features HxWxCxT 20x80x256x60), this vector space seems to be an ego-centric 2d birds-eye view</li>
<li>Late fusion
Detection on 2d images and then back-project to 3d</li>
<li>early fusion: not so early
back-bone on each 2d image; fuse to vector space; heads on vector space</li>
</ul>
</div>
</div>

<div id="outline-container-orgf35c70a" class="outline-2">
<h2 id="orgf35c70a">Transformer for fuse / back-project</h2>
<div class="outline-text-2" id="text-orgf35c70a">
<ul class="org-ul">
<li>each image provides keys and values</li>
<li>positional encoded 3d grid / 2d birds-eye view grid are the queries</li>
<li>Transformer is doing the data-dependent back-project part</li>
</ul>
</div>
</div>

<div id="outline-container-org10bba62" class="outline-2">
<h2 id="org10bba62">Camera rectify</h2>
<div class="outline-text-2" id="text-org10bba62">
<ul class="org-ul">
<li>It sounds like correct the camera orientation error during installation by software composition.</li>
<li>This is before everything. It is like pre-processing.</li>
</ul>
</div>
</div>

<div id="outline-container-orgd3b169f" class="outline-2">
<h2 id="orgd3b169f">Video Queue</h2>
<div class="outline-text-2" id="text-orgd3b169f">
<ul class="org-ul">
<li>Queue is going into an RNN.</li>
<li>Features: Kinematics(velocity and acceleration) + vector space features + positional encodings</li>
<li>time queue: push stuff in every certain time</li>
<li>spatial queue: push stuff in when the car travels a certain distance.</li>
<li>This can be thought as fusing time and space. And it is a late fusion again. The future direction is to do early fusion using optical flow / cost volume??</li>
</ul>
</div>
</div>

<div id="outline-container-orgf89c5af" class="outline-2">
<h2 id="orgf89c5af">Spatial RNN</h2>
<div class="outline-text-2" id="text-orgf89c5af">
<ul class="org-ul">
<li>This sounds like a larger/global 2d birds-eye view which is not ego-centric.</li>
<li>And you only update the area that the car can "see" in its ego-centric vector space.</li>
<li>However, how large is this non-ego-centric birds-eye view is unknown. And how this large tensor can be stored in memory is unknown.</li>
</ul>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="validation"></p>
</div>
</body>
</html>
