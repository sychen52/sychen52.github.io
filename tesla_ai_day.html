<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="generator" content="Org mode" />
<link rel="stylesheet" type="text/css" href="https://gongzhitaao.org/orgcss/org.css"/>
</head>
<body>
<div id="content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgaa286a1">Cache feature maps on disk</a></li>
<li><a href="#orge843458">Late fusion -&gt; early fusion</a></li>
<li><a href="#org510925c">Transformer for fuse / back-project</a></li>
<li><a href="#orgfe8f0e4">Camera rectify</a></li>
<li><a href="#org5afeaf2">Video Queue</a></li>
<li><a href="#orgb4a9797">Spatial RNN</a></li>
</ul>
</div>
</div>
<p>
<a href="https://www.youtube.com/watch?v=j0z4FweCy4M">https://www.youtube.com/watch?v=j0z4FweCy4M</a>
</p>

<div id="outline-container-orgaa286a1" class="outline-2">
<h2 id="orgaa286a1">Cache feature maps on disk</h2>
<div class="outline-text-2" id="text-orgaa286a1">
<ul class="org-ul">
<li>shared back-bone + multiple heads;</li>
<li>back-bone output feature maps are cached on disk;</li>
<li>fine-tune heads based on cached features.</li>
</ul>
</div>
</div>

<div id="outline-container-orge843458" class="outline-2">
<h2 id="orge843458">Late fusion -&gt; early fusion</h2>
<div class="outline-text-2" id="text-orge843458">
<ul class="org-ul">
<li>vector space: 3d space, 2d birds-eye view
From the later slides (Multi-Cam Features HxWxCxT 20x80x256x60), this vector space seems to be an ego-centric 2d birds-eye view</li>
<li>Late fusion
Detection on 2d images and then back-project to 3d</li>
<li>early fusion: not so early
back-bone on each 2d image; fuse to vector space; heads on vector space</li>
</ul>
</div>
</div>

<div id="outline-container-org510925c" class="outline-2">
<h2 id="org510925c">Transformer for fuse / back-project</h2>
<div class="outline-text-2" id="text-org510925c">
<ul class="org-ul">
<li>each image provides keys and values</li>
<li>positional encoded 3d grid / 2d birds-eye view grid are the queries</li>
<li>Transformer is doing the data-dependent back-project part</li>
</ul>
</div>
</div>

<div id="outline-container-orgfe8f0e4" class="outline-2">
<h2 id="orgfe8f0e4">Camera rectify</h2>
<div class="outline-text-2" id="text-orgfe8f0e4">
<ul class="org-ul">
<li>It sounds like correct the camera orientation error during installation by software composition.</li>
<li>This is before everything. It is like pre-processing.</li>
</ul>
</div>
</div>

<div id="outline-container-org5afeaf2" class="outline-2">
<h2 id="org5afeaf2">Video Queue</h2>
<div class="outline-text-2" id="text-org5afeaf2">
<ul class="org-ul">
<li>Queue is going into an RNN.</li>
<li>Features: Kinematics(velocity and acceleration) + vector space features + positional encodings</li>
<li>time queue: push stuff in every certain time</li>
<li>spatial queue: push stuff in when the car travels a certain distance.</li>
<li>This can be thought as fusing time and space. And it is a late fusion again. The future direction is to do early fusion using optical flow / cost volume??</li>
</ul>
</div>
</div>

<div id="outline-container-orgb4a9797" class="outline-2">
<h2 id="orgb4a9797">Spatial RNN</h2>
<div class="outline-text-2" id="text-orgb4a9797">
<ul class="org-ul">
<li>This sounds like a larger/global 2d birds-eye view which is not ego-centric.</li>
<li>And you only update the area that the car can "see" in its ego-centric vector space.</li>
<li>However, how large is this non-ego-centric birds-eye view is unknown. And how this large tensor can be stored in memory is unknown.</li>
</ul>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="validation"></p>
</div>
</body>
</html>
