<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="generator" content="Org mode" />
<link rel="stylesheet" type="text/css" href="https://orgmode.org/worg/style/worg.css"/>
</head>
<body>
<div id="content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org2b6787a">3d representation</a></li>
<li><a href="#org14e7b62">From 2d image to depth map:</a></li>
<li><a href="#org39fbde7">From 2d image to 3d voxel grid:</a></li>
<li><a href="#org4635a0e">From 2d image to point cloud</a></li>
<li><a href="#org7c6c719">From 2d image to mesh</a></li>
<li><a href="#orgedc0b8a">Model on 3d:</a></li>
<li><a href="#org0819c57">Mean Average Precision (mAP) in Object detection</a>
<ul>
<li><a href="#org6fd2377">AP = area under Precision vs. Recall Curve</a></li>
<li><a href="#org28fc88b">mAP</a></li>
</ul>
</li>
<li><a href="#org097a96f">R-CNN</a></li>
<li><a href="#org81b6597">Fast R-CNN</a></li>
<li><a href="#org386e1e8">Faster R-CNN</a></li>
<li><a href="#org2aa779d">Single Stage Object Detection (SSD)</a></li>
</ul>
</div>
</div>
<p>
#+title Deep Learning for Computer Vision
</p>
<div id="outline-container-org2b6787a" class="outline-2">
<h2 id="org2b6787a">3d representation</h2>
<div class="outline-text-2" id="text-org2b6787a">
<ul class="org-ul">
<li>depth map</li>
<li>voxel grid</li>
<li>point cloud</li>
<li>mesh</li>
<li>implicit function</li>
</ul>
</div>
</div>

<div id="outline-container-org14e7b62" class="outline-2">
<h2 id="org14e7b62">From 2d image to depth map:</h2>
<div class="outline-text-2" id="text-org14e7b62">
<p>
unet2d
</p>
</div>
</div>
<div id="outline-container-org39fbde7" class="outline-2">
<h2 id="org39fbde7">From 2d image to 3d voxel grid:</h2>
<div class="outline-text-2" id="text-org39fbde7">
<ul class="org-ul">
<li>Fully connected</li>
<li>Transformer</li>
<li>voxel tube (channel dimension as the z-axis of the camera)</li>
</ul>
</div>
</div>

<div id="outline-container-org4635a0e" class="outline-2">
<h2 id="org4635a0e">From 2d image to point cloud</h2>
<div class="outline-text-2" id="text-org4635a0e">
<ul class="org-ul">
<li>FC</li>
<li>Transformer</li>
</ul>
</div>
</div>

<div id="outline-container-org7c6c719" class="outline-2">
<h2 id="org7c6c719">From 2d image to mesh</h2>
<div class="outline-text-2" id="text-org7c6c719">
<p>
2d image -&gt; 3d mask on a grid -&gt; mesh -&gt; deformed mesh
</p>
</div>
</div>

<div id="outline-container-orgedc0b8a" class="outline-2">
<h2 id="orgedc0b8a">Model on 3d:</h2>
<div class="outline-text-2" id="text-orgedc0b8a">
<ul class="org-ul">
<li>voxel grid: conv3d</li>
<li>point cloud: point-wise MLP (conv1d with kernel size 1)</li>
<li>mesh: graph convolution</li>
</ul>
</div>
</div>

<div id="outline-container-org0819c57" class="outline-2">
<h2 id="org0819c57">Mean Average Precision (mAP) in Object detection</h2>
<div class="outline-text-2" id="text-org0819c57">
<p>
<a href="https://youtu.be/TB-fdISzpHQ?t=2230">https://youtu.be/TB-fdISzpHQ?t=2230</a>
</p>
</div>
<div id="outline-container-org6fd2377" class="outline-3">
<h3 id="org6fd2377">AP = area under Precision vs. Recall Curve</h3>
<div class="outline-text-3" id="text-org6fd2377">
<ul class="org-ul">
<li>Pick a class (e.g. dog), and a threshold for IoU (e.g. 0.5, IoU &gt; 0.5 means detected)</li>
<li>Sort all the predicted boxes by the probability of dog class.</li>
<li>Iterator all these boxes from high probability to low
<ul class="org-ul">
<li>Compute the Precision and Recall as if you set the threshold of probability to be the current value.</li>
<li>IoU &gt; 0.5 means detected, otherwise not</li>
</ul></li>
<li>plot this Precision and Recall curve and compute</li>
</ul>

<p>
To get AP=1, hit all GT boxes with IoU &gt; 0.5 and have no FP detections ranked abover any TP
</p>
</div>
</div>
<div id="outline-container-org28fc88b" class="outline-3">
<h3 id="org28fc88b">mAP</h3>
<div class="outline-text-3" id="text-org28fc88b">
<p>
repeat AP for all classes, some different IoU thresholds.
</p>
</div>
</div>
</div>

<div id="outline-container-org097a96f" class="outline-2">
<h2 id="org097a96f">R-CNN</h2>
<div class="outline-text-2" id="text-org097a96f">
<p>
non-DL region proposal; Resample the image in each region; CNN on each region; a class and bounding box per region;
</p>
</div>
</div>

<div id="outline-container-org81b6597" class="outline-2">
<h2 id="org81b6597">Fast R-CNN</h2>
<div class="outline-text-2" id="text-org81b6597">
<p>
CNN on the entire image; non-DL region proposal; Resample the CNN feature in each region (e.g. into 7x7); small CNN on each region; a class and bounding box per region;
</p>
</div>
</div>

<div id="outline-container-org386e1e8" class="outline-2">
<h2 id="org386e1e8">Faster R-CNN</h2>
<div class="outline-text-2" id="text-org386e1e8">
<p>
same as Fast R-CNN, expect DL region proposal:
On the CNN output feature map, add another CNN. every position on its output is a (K) anchor box(es): (a probability of being a region, the bbox).
</p>
</div>
</div>

<div id="outline-container-org2aa779d" class="outline-2">
<h2 id="org2aa779d">Single Stage Object Detection (SSD)</h2>
<div class="outline-text-2" id="text-org2aa779d">
<p>
All R-CNNs have two stages: region proposal + final bbox.
SSD only has the first stage of Faster R-CNN.
CNN on the entire image. Instead of a DL based region proposal, SSD outputs the class and the bbox at these anchor box directly.
SSD is 10x faster than Faster R-CNN but not as accurate.
</p>

<script src="https://utteranc.es/client.js"
        repo="sychen52/sychen52.github.io"
        issue-term="pathname"
        theme="github"
        crossorigin="anonymous"
        async>
</script>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="validation"></p>
</div>
</body>
</html>
