<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Is Julia Ready for Deep Learning</title>
<meta name="generator" content="Org mode" />
<meta name="keywords" content="Julialang, Julia, deep learning, DL" />
<link rel="stylesheet" href="https://cdn.simplecss.org/simple.min.css" />
</head>
<body>
<div id="content">
<h1 class="title">Is Julia Ready for Deep Learning</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#memory-management">Memory Management</a></li>
<li><a href="#speed">Speed</a></li>
<li><a href="#ahead-of-time-aot-compilation-vs.-just-in-time-jit-compilation-vs.-interpreter">Ahead of Time (AOT) Compilation vs. Just In Time (JIT) Compilation vs. Interpreter</a></li>
<li><a href="#community">Community</a></li>
<li><a href="#solve-two-language-problem">Solve Two Language Problem</a></li>
<li><a href="#deep-learning-library-and-auto-differentiation-ad">Deep Learning Library and Auto Differentiation (AD)</a></li>
</ul>
</div>
</div>
<p>
I heard about Swift and Julia for deep learning during
<a href="https://www.youtube.com/watch?v=3TqN_M1L4ts">fast.ai's course</a>. Then
I spent quite some time to try figuring out whether any of these
languages is a better choice for deep learning than Python. However,
soon I realized that Chris Lattner left Google and Swift for Tensorflow
project is slowing down and even <a href="https://twimlai.com/whats-next-for-fast-ai-w-jeremy-howard/">Jeremy
Howard is less passionate about it</a>. Then the only choice left for now
is Julia AFAIK. The Question is whether Julia is ready for deep
learning.
</p>

<div id="outline-container-org7f23d96" class="outline-2">
<h2 id="memory-management"><a id="org7f23d96"></a>Memory Management</h2>
<div class="outline-text-2" id="text-memory-management">
<p>
I noticed this issue when Chris Lattner pointed during a
<a href="https://twimlai.com/the-great-ml-language-un-debate/">debate</a>. In
short, Julia uses the Garbage Collector. It may cause memory not being
released in time. This is especially problematic for GPU since its
memory is much smaller than CPU memory. The good news is there is some
<a href="https://juliagpu.gitlab.io/CUDA.jl/usage/memory/">workaround</a>, but it
would be better if Julia has some deterministic memory management. There
is an
<a href="https://discourse.julialang.org/t/proposal-for-deterministic-memory-management/39305">ongoing
discussion about this</a>.
</p>
</div>
</div>

<div id="outline-container-org8390df8" class="outline-2">
<h2 id="speed"><a id="org8390df8"></a>Speed</h2>
<div class="outline-text-2" id="text-speed">
<p>
I guess most people come to Julia for speed. However, to get the optimal
speed, it is not that straight forward. One problem is to
<a href="https://www.youtube.com/watch?v=o8qTJGcPWkE">avoid allocation</a>.
Another problem is type inference. Julia is a dynamic typing language;
however, to get the best speed, you are encouraged to have type
annotation and type stability. The purpose of this is to make it easy
for people who do not care about the speed that much. However, I think
static typing can make things much more straightforward. This leads to
the next point I would like to mention
</p>
</div>
</div>

<div id="outline-container-org7619792" class="outline-2">
<h2 id="ahead-of-time-aot-compilation-vs.-just-in-time-jit-compilation-vs.-interpreter"><a id="org7619792"></a>Ahead of Time (AOT) Compilation vs. Just In Time (JIT) Compilation vs. Interpreter</h2>
<div class="outline-text-2" id="text-ahead-of-time-aot-compilation-vs.-just-in-time-jit-compilation-vs.-interpreter">
<p>
Usually, static typing languages are AOT compiled while
dynamic language runs on an interpreter, and sometimes with a
JIT compiler. Because you need to know the type to deeply optimize the
code, static typing languages can directly be optimized AOT, while
dynamic typing languages can only to optimized at runtime when the
type is known with a JIT. Julia is somewhere in between. It is
<a href="https://www.youtube.com/watch?v=XWIZ_dCO6X8">just ahead of time
(JAOT)</a> compiled. Julia does type inference as early as it can. But for a
dynamic type language, inevitably, the type cannot be inferred before runtime.
The pro is that you have a deeply optimized dynamic
typing language. The con is this JAOT takes a long time, and this is the
well known time to first plot issue. This issue is not a big deal if you
use Julia for deep learning. However, dynamic typing is something built
in the design of the language, while you enjoy the ease of use, you also
have to bear with the awkwardness it brings: 1) long JAOT compilation
time; 2) hard to build into libraries and executables. Luckily, both of
these two are somewhat solved by
<a href="https://github.com/JuliaLang/PackageCompiler.jl">PackageCompiler.jl</a>,
but awkwardly IMO.
</p>
</div>
</div>

<div id="outline-container-org0ab1cfa" class="outline-2">
<h2 id="community"><a id="org0ab1cfa"></a>Community</h2>
<div class="outline-text-2" id="text-community">
<p>
Julia has a large scientific computing community. For deep learning,
there is also a community working on the
<a href="https://github.com/FluxML/ML-Coordination-Tracker">machine learning
ecosystem</a>.
</p>
</div>
</div>

<div id="outline-container-org5d162f1" class="outline-2">
<h2 id="solve-two-language-problem"><a id="org5d162f1"></a>Solve Two Language Problem</h2>
<div class="outline-text-2" id="text-solve-two-language-problem">
<p>
I think this is a pretty unique point about Julia. People are proud of
using Julia from high-level all the way to low-level programming. The
fact that Julia can be used to do
<a href="https://www.youtube.com/watch?v=525t9-nsn5Y">CUDA programming</a> just
blew my mind. Keep in mind that when you get into the advanced
metaprogramming in Julia, it feels quite different compared to the part
of Julia you normally use but it is technically still Julia language.
</p>
</div>
</div>

<div id="outline-container-org501a2f6" class="outline-2">
<h2 id="deep-learning-library-and-auto-differentiation-ad"><a id="org501a2f6"></a>Deep Learning Library and Auto Differentiation (AD)</h2>
<div class="outline-text-2" id="text-deep-learning-library-and-auto-differentiation-ad">
<p>
I guess a lot of people care about this the most. The reason I put it at
the very end is that it is not very mature yet. The most promising deep
learning library is called
<a href="https://github.com/FluxML/Flux.jl">Flux.jl</a> and the AD it uses is
called <a href="https://github.com/FluxML/Zygote.jl">Zygote.jl</a>. They are
still undergoing some changes. As far as I know, there may be a
<a href="https://youtu.be/mQnSRfseu0c">new AD</a> coming out to replace Zygote.
Unlike Pytorch, where AD only works on Pytorch's Tensor class, Zygote is
a source to source AD that does not need to introduce another Tensor
class, it just works on the existing data structure. This can be a huge
advantage for developers. In Pytorch ecosystem, to be differentiable,
developers need to re-write their libraries using Pytorch's Tensor. For
example, <a href="https://github.com/kornia/kornia">Kornia</a> is a re-write of
OpenCV using Pytorch. This will not happen to Julia package developer
since the AD will just work.
</p>

<p>
To summary up, IMHO, this is a very good time for early adopters and
people who want to make contributions. However, if you just want to get
things done, or you want the current best (fast and fully functional)
solution, Julia is not ready yet.
</p>

<script src="https://utteranc.es/client.js"
        repo="sychen52/sychen52.github.io"
        issue-term="pathname"
        theme="github-dark"
        crossorigin="anonymous"
        async>
</script>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Date: 2020-11-10 Tue 00:00</p>
<p class="validation"></p>
</div>
</body>
</html>
